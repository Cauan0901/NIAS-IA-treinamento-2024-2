{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates\n",
    "# Dates in pandas are represented by the Timestamp data type. We can use the pd.to_datetime() \n",
    "# function to convert strings to Timestamp objects. \n",
    "# This function is very flexible and can convert strings in many formats into Timestamp objects. \n",
    "# We can also specify the format that the dates are in, which can speed up the conversion process. Here's an example:\n",
    "earthquakes.loc[3378, \"Date\"] = \"02/23/1975\"\n",
    "earthquakes.loc[7512, \"Date\"] = \"04/28/1985\"\n",
    "earthquakes.loc[20650, \"Date\"] = \"03/13/2011\"\n",
    "earthquakes['date_parsed'] = pd.to_datetime(earthquakes[\"Date\"], format=\"%m/%d/%Y\")\n",
    "\n",
    "# select the day of the month\n",
    "day_of_month_earthquakes = earthquakes['date_parsed'].dt.day\n",
    "\n",
    "sns.distplot(day_of_month_earthquakes, kde=False, bins=31) # Plot the day of the month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "\n",
    "missing_values_count = df_data.isnull().sum()\n",
    "# how many total missing values do we have?\n",
    "total_cells = np.product(nfl_data.shape)\n",
    "total_missing = missing_values_count.sum()\n",
    "\n",
    "# percent of data that is missing\n",
    "percent_missing = (total_missing/total_cells) * 100\n",
    "print(percent_missing)\n",
    "\n",
    "# remove all the rows that contain a missing value\n",
    "df_data.dropna()\n",
    "\n",
    "# remove all columns with at least one missing value\n",
    "columns_with_na_dropped = df_data.dropna(axis=1)\n",
    "\n",
    "# replace all NA's with 0\n",
    "df_data.fillna(0)\n",
    "# replace all NA's the value that comes directly after it in the same column, \n",
    "# then replace all the remaining na's with 0\n",
    "df_data.fillna(method='bfill', axis=0).fillna(0) # Substitute the missing values with the next value in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling and Normalization\n",
    "\n",
    "#imports\n",
    "# for Box-Cox Transformation\n",
    "from scipy import stats\n",
    "\n",
    "# for min_max scaling\n",
    "from mlxtend.preprocessing import minmax_scaling\n",
    "\n",
    "scaled_data = minmax_scaling(original_data, columns=[0])\n",
    "\n",
    "# plot both together to compare\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 3))\n",
    "sns.histplot(original_data, ax=ax[0], kde=True, legend=False)\n",
    "ax[0].set_title(\"Original Data\")\n",
    "sns.histplot(scaled_data, ax=ax[1], kde=True, legend=False)\n",
    "ax[1].set_title(\"Scaled data\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# normalize the exponential data with boxcox\n",
    "normalized_data = stats.boxcox(original_data)\n",
    "\n",
    "# plot both together to compare\n",
    "fig, ax=plt.subplots(1, 2, figsize=(15, 3))\n",
    "sns.histplot(original_data, ax=ax[0], kde=True, legend=False)\n",
    "ax[0].set_title(\"Original Data\")\n",
    "sns.histplot(normalized_data[0], ax=ax[1], kde=True, legend=False)\n",
    "ax[1].set_title(\"Normalized data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalling\n",
    "![Imagem](Scalling.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization\n",
    "![Exemplo de Imagem](Normalization.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characters Encoding  \n",
    "\n",
    "# modules we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# helpful character encoding module\n",
    "import charset_normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xa7A\\xa6n'\n",
      "data type: <class 'bytes'>\n",
      "你好\n"
     ]
    }
   ],
   "source": [
    "sample_entry = b'\\xa7A\\xa6n'\n",
    "print(sample_entry)\n",
    "print('data type:', type(sample_entry))\n",
    "\n",
    "# changes the encoding from \"big5-tw\" to \"utf-8\"\n",
    "before = sample_entry.decode(\"big5-tw\")\n",
    "new_entry = before.encode()\n",
    "\n",
    "\n",
    "# read a file with encoding problems\n",
    "files = pd.read_csv(\"...\", encoding='FORMAT')\n",
    "result = charset_normalizer.detect(rawdata.read(10000)) # Detect the encoding of the file\n",
    "print(result)\n",
    "\n",
    "\n",
    "# Save in CSV format\n",
    "files.to_csv(\"my_file.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inconsistent Data Entry\n",
    "\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "import charset_normalizer\n",
    "\n",
    "\n",
    "\n",
    "array([' Germany', ' New Zealand', ' Sweden', ' USA', 'Australia',\n",
    "       'Austria', 'Canada', 'China', 'Finland', 'France', 'Greece',\n",
    "       'HongKong', 'Ireland', 'Italy', 'Japan', 'Macau', 'Malaysia',\n",
    "       'Mauritius', 'Netherland', 'New Zealand', 'Norway', 'Pakistan',\n",
    "       'Portugal', 'Russian Federation', 'Saudi Arabia', 'Scotland',\n",
    "       'Singapore', 'South Korea', 'SouthKorea', 'Spain', 'Sweden',\n",
    "       'Thailand', 'Turkey', 'UK', 'USA', 'USofA', 'Urbana', 'germany'],\n",
    "      dtype=object)\n",
    "\n",
    "# Germany and germany should be the same, ' New Zealand' and 'New Zealand' should be the same.\n",
    "\n",
    "# Transformando os nomes e minusculos e removendo espaços, assim os nomes ficam padronizados e se juntam.\n",
    "array = array.str.strip()\n",
    "array = array.str.lower()\n",
    "\n",
    "# Fuzzy matching: The process of automatically finding text strings that are very similar to the target string. \n",
    "# In general, a string is considered \"closer\" to another one the fewer characters you'd need to change \n",
    "# if you were transforming one string into another.\n",
    "\n",
    "# South Korea and SouthKorea should be the same country.\n",
    "# get the top 10 closest matches to \"south korea\"\n",
    "matches = fuzzywuzzy.process.extract(\"south korea\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "# function to replace rows in the provided column of the provided dataframe\n",
    "# that match the provided string above the provided ratio with the provided string\n",
    "def replace_matches_in_column(df, column, string_to_match, min_ratio = 47):\n",
    "    # get a list of unique strings\n",
    "    strings = df[column].unique()\n",
    "    \n",
    "    # get the top 10 closest matches to our input string\n",
    "    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n",
    "                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "    # only get matches with a ratio > 90\n",
    "    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n",
    "\n",
    "    # get the rows of all the close matches in our dataframe\n",
    "    rows_with_matches = df[column].isin(close_matches)\n",
    "\n",
    "    # replace all rows with close matches with the input matches \n",
    "    df.loc[rows_with_matches, column] = string_to_match\n",
    "    \n",
    "    # let us know the function's done\n",
    "    print(\"All done!\")\n",
    "\n",
    "    replace_matches_in_column(df=professors, column='Country', string_to_match=\"south korea\")\n",
    "\n",
    "    array(['australia', 'austria', 'canada', 'china', 'finland', 'france',\n",
    "       'germany', 'greece', 'hongkong', 'ireland', 'italy', 'japan',\n",
    "       'macau', 'malaysia', 'mauritius', 'netherland', 'new zealand',\n",
    "       'norway', 'pakistan', 'portugal', 'russian federation',\n",
    "       'saudi arabia', 'scotland', 'singapore', 'south korea', 'spain',\n",
    "       'sweden', 'thailand', 'turkey', 'uk', 'urbana', 'usa', 'usofa'],\n",
    "      dtype=object)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VRM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
